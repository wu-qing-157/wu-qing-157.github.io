---
permalink: /
title: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

I'm Yi Gu (顾逸, gù yì), a second year Ph.D. student in Data Science at [Halıcıoğlu Data Science Institute](https://datascience.ucsd.edu) of UC San Diego.
I'm fortunate to be advised by [Prof. Zhiting Hu](https://zhiting.ucsd.edu).

Prior to joining UCSD, I obtained my B.ENG. degree at [ACM Honors Class](https://acm.sjtu.edu.cn/home),
[Shanghai Jiao Tong University](https://www.sjtu.edu.cn) in June 2022,
advised by [Prof. Yong Yu](https://apex.sjtu.edu.cn/members/yyu).

My research interest lies in foundational models and reasonings.
In particular,
I am recently working on the reasoning ability of nowadays LLMs ([RAP](#rap), [Reasoners](#reasoners)),
and also building World Models ([Pandora](#pandora)),
aiming for the next-generation machine reasoning beyond LLMs.

Selected Publications
======
<a name="pandora"></a>
**Pandora: Towards General World Model with Natural Language Actions and Video States**\
Jiannan Xiang\*, Guangyi Liu\*, **Yi Gu**\*, Qiyue Gao, Yuting Ning, Yuheng Zha, Zeyu Feng, Tianhua Tao, Shibo Hao, Yemin Shi, Zhengzhong Liu， Eric P. Xing, Zhiting Hu\
***Preprint*** [[Website]](https://world-model.ai) [[YouTube]](https://www.youtube.com/watch?v=nSKqr1Fl91g) [[Code]](https://github.com/maitrix-org/Pandora) [[Paper]](https://world-model.maitrix.org/assets/pandora.pdf)

<a name="reasoners"></a>
**LLM Reasoners: New Evaluation, Library, and Analysis of Step-by-Step Reasoning with Large Language Models**\
Shibo Hao\*, **Yi Gu**\*, Haotian Luo\*, Tianyang Liu, Xiyan Shao, Xinyuan Wang, Shuhua Xie, Haodi Ma, Adithya Samavedhi, Qiyue Gao, Zhen Wang, Zhiting Hu\
***Preprint*** [[Website]](https://www.llm-reasoners.net) [[Library]](https://github.com/maitrix-org/llm-reasoners) [[Paper]](https://arxiv.org/abs/2404.05221)

<a name="rap"></a>
**Reasoning with Language Model is Planning with World Model**\
Shibo Hao\*, **Yi Gu**\*, Haodi Ma, Joshua Jiahua Hong, Zhen Wang, Daisy Zhe Wang, Zhiting Hu\
***EMNLP 2023*** [[Paper]](https://arxiv.org/abs/2305.14992) [[Code]](https://github.com/Ber666/RAP) [[State of AI Report 2023]](https://docs.google.com/presentation/d/156WpBF_rGvf4Ecg19oM1fyR51g4FAmHV3Zs0WLukrLQ/edit#slide=id.g24daeb7f4f0_0_3930)

<a name="k2"></a>
**LLM360 K2-65B: Scaling Up Fully Transparent Open-Source LLMs**\
Zhengzhong Liu, Bowen Tan, Hongyi Wang, Willie Neiswanger, Tianhua Tao, Haonan Li, Fajri Koto, Yuqi Wang, Suqi Sun, Omkar Pangarkar, Richard Fan, **Yi Gu**, Victor Miller, Liqun Ma, Liping Tang, Nikhil Ranjan, Yonghao Zhuang, Guowei He, Renxi Wang,Mingkai Deng, Robin Algayres, Yuanzhi Li, Zhiqiang Shen, Preslav Nakov, Eric Xing\
***Preprint*** [[Blog]](https://www.llm360.ai/blog/several-new-releases-to-further-our-mission.html) [[Paper]](https://www.llm360.ai/paper2.pdf) [[Weights]](https://huggingface.co/LLM360/K2)

\* indicates equal contribution

Honors and Awards
======
Zhiyuan Outstanding Student Scholarship, 2022\
National Scholarship of P.R. China, 2021\
Rong Chang Scholarship in Technological Innovation, 2020\
Rong Chang Scholarship in Technological Innovation, 2019\
*Gold Medal*, The International Collegiate Programming Contest (ICPC) 2019 Xuzhou Site\
*Champion*, The International Collegiate Programming Contest (ICPC) 2018 Singapore Site


<sub><sup>Updated on June 4, 2024</sup></sub>